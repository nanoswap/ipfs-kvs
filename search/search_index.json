{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"IPFS Key Value Store github.com/nanoswap/ipfs-kvs Wrappers for IPFS RPC endpoints import ipfs client = ipfs.Ipfs() # defaults to http://127.0.0.1:5001/api/v0 client.mkdir(\"my_dir\") client.add(\"my_dir/my_file\", b\"my_contents\") Read and write protobuf contents Reading: from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), reader=MyProtobuf() ) store.read() print(store.reader) Writing: from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), writer=MyProtobuf() ) store.add() Overhead for nested directories Write with multiple indexes Create a tiered file structure based on IDs, ex: \u251c\u2500\u2500 fashion/ \u251c\u2500\u2500 designer_1.manufacturer_1 \u251c\u2500\u2500 designer_2.manufacturer_1 \u251c\u2500\u2500 deal_16.data \u251c\u2500\u2500 designer_4.manufacturer_3 \u251c\u2500\u2500 deal_1.data \u251c\u2500\u2500 deal_2.data from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal index = Index( prefix=\"fashion\", index={ \"designer\": str(uuid.uuid4()), \"manufacturer\": str(uuid.uuid4()) }, subindex=Index( index={ \"deal\": str(uuid.uuid4()) } ) ) data = Deal(type=Type.BUZZ, content=\"fizz\") store = Store(index=index, ipfs=Ipfs(), writer=data) store.add() Query the multiple indexes Ex: get all deals with designer id \"123\" from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal query_index = Index( prefix=\"fashion\", index={ \"designer\": \"123\" } ) reader = Deal() query_results = Store.query(query_index, ipfs, reader) print(Store.to_dataframe(query_results))","title":"Home"},{"location":"#ipfs-key-value-store","text":"github.com/nanoswap/ipfs-kvs","title":"IPFS Key Value Store"},{"location":"#wrappers-for-ipfs-rpc-endpoints","text":"import ipfs client = ipfs.Ipfs() # defaults to http://127.0.0.1:5001/api/v0 client.mkdir(\"my_dir\") client.add(\"my_dir/my_file\", b\"my_contents\")","title":"Wrappers for IPFS RPC endpoints"},{"location":"#read-and-write-protobuf-contents","text":"","title":"Read and write protobuf contents"},{"location":"#reading","text":"from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), reader=MyProtobuf() ) store.read() print(store.reader)","title":"Reading:"},{"location":"#writing","text":"from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), writer=MyProtobuf() ) store.add()","title":"Writing:"},{"location":"#overhead-for-nested-directories","text":"","title":"Overhead for nested directories"},{"location":"#write-with-multiple-indexes","text":"Create a tiered file structure based on IDs, ex: \u251c\u2500\u2500 fashion/ \u251c\u2500\u2500 designer_1.manufacturer_1 \u251c\u2500\u2500 designer_2.manufacturer_1 \u251c\u2500\u2500 deal_16.data \u251c\u2500\u2500 designer_4.manufacturer_3 \u251c\u2500\u2500 deal_1.data \u251c\u2500\u2500 deal_2.data from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal index = Index( prefix=\"fashion\", index={ \"designer\": str(uuid.uuid4()), \"manufacturer\": str(uuid.uuid4()) }, subindex=Index( index={ \"deal\": str(uuid.uuid4()) } ) ) data = Deal(type=Type.BUZZ, content=\"fizz\") store = Store(index=index, ipfs=Ipfs(), writer=data) store.add()","title":"Write with multiple indexes"},{"location":"#query-the-multiple-indexes","text":"Ex: get all deals with designer id \"123\" from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal query_index = Index( prefix=\"fashion\", index={ \"designer\": \"123\" } ) reader = Deal() query_results = Store.query(query_index, ipfs, reader) print(Store.to_dataframe(query_results))","title":"Query the multiple indexes"},{"location":"LICENSE/","text":"This is free and unencumbered software released into the public domain. Anyone is free to copy, modify, publish, use, compile, sell, or distribute this software, either in source code form or as a compiled binary, for any purpose, commercial or non-commercial, and by any means. In jurisdictions that recognize copyright laws, the author or authors of this software dedicate any and all copyright interest in the software to the public domain. We make this dedication for the benefit of the public at large and to the detriment of our heirs and successors. We intend this dedication to be an overt act of relinquishment in perpetuity of all present and future rights to this software under copyright law. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. For more information, please refer to https://unlicense.org","title":"License"},{"location":"classes_index/","text":"Index src.index.Index An object for storing a nested directory structure. Use the Store class to read or write the data for an Index. Convert a filename to an Index object index = Index.from_filename(\"mydir/show_1/season_2/episode_6.mp4\") Convert an Index object to a filename filename = index.get_filename() Source code in src/index.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 class Index (): \"\"\"An object for storing a nested directory structure. Use the `Store` class to read or write the data for an Index. ### Convert a filename to an Index object ```py index = Index.from_filename(\"mydir/show_1/season_2/episode_6.mp4\") ``` ### Convert an Index object to a filename ```py filename = index.get_filename() ``` \"\"\" prefix : str index : Dict [ str , UUID ] size : int # number of keys in this index (not including parent or subindex) # noqa: E501 subindex : Index def __init__ ( self : Self , index : Dict [ str , UUID ], subindex : Index = None , prefix : str = None , size : int = None ) -> None : \"\"\"Index Constructor. Index keys should be all one word lower case. Index values should be UUIDs. \"\"\" self . prefix = prefix self . index = index self . subindex = subindex self . size = size if size else len ( index . keys ()) def __str__ ( self : Self ) -> str : \"\"\"Convert an Index to a string with `str()`. This will recursively parse the subindexes and include them all in the response. Returns: str: The index object as a string \"\"\" return json . dumps ( self . to_dict (), sort_keys = True , indent = 4 ) def __eq__ ( self : Self , other_index : Index ) -> bool : \"\"\"Compare two Index objects with `==`. Args: other_index (Index): The other index to compare Returns: bool: Returns true if self == other_index \"\"\" result = \\ self . prefix == other_index . prefix and \\ self . size == other_index . size and \\ self . subindex == other_index . subindex and \\ self . index == other_index . index return result def to_dict ( self : Self ) -> dict : \"\"\"Convert the Index object to a dictionary. This will recursively parse the subindexes and include them all in the response. Returns: dict: The index object as a dict \"\"\" return { \"prefix\" : self . prefix , \"index\" : self . index , \"subindex\" : self . subindex . to_dict () if self . subindex else None } def matches ( self : Self , other_index : Index ) -> bool : \"\"\"Check if this index has a compatible index with another index. Args: other_index (Index): The other index object to compare against Returns: bool: Returns false if any self keys are not in the other index or if any values in self are not equal to the corresponding value in the other index \"\"\" for key in self . index : if key not in other_index . index : return False if str ( self . index [ key ]) != str ( other_index . index [ key ]): return False return True def is_partial ( self : Self ) -> bool : \"\"\"Check if the index has less keys than expected. Returns: bool: Returns true if some keys are missing \"\"\" return self . size != len ( self . index . keys ()) def get_metadata ( self : Self ) -> Dict [ str , UUID ]: \"\"\"Parse the subindex/filename data. This will recursively parse the subindexes and include them all in the response. Returns: Dict[str, UUID]: A flat map of (key: value) \"\"\" filename = self . get_filename () # recursively get subindex data records = filename . split ( \"/\" ) if self . prefix : records . pop ( 0 ) result = {} for index_level in records : for index in index_level . split ( \".\" ): result [ index . split ( \"_\" )[ 0 ]] = index . split ( \"_\" )[ 1 ] return result def get_filename ( self : Self ) -> str : \"\"\"Convert this object to a filename. Returns: str: The filename for this Index \"\"\" result = \"\" # Add prefix if self . prefix : result += self . prefix + \"/\" # If not all index keys are known, don't add it to the filename if self . is_partial (): return result # Add current index cur_index = \".\" . join ([ f ' { key } _ { value } ' for key , value in self . index . items () ]) result += cur_index # Recursively add subindexes if self . subindex : result += \"/\" + self . subindex . get_filename () return result @staticmethod def from_filename ( filename : str , has_prefix : bool = False ) -> Index : \"\"\"Convert a filename to an Index object. Args: filename (str): The filename to verify has_prefix (bool, optional): Does the filename have a prefix? Defaults to False. Raises: Exception: If the filename is unable to be parsed an exception will be raised Returns: Index: The index object with data corresponding to the input filename \"\"\" directories = [ file for file in filename . split ( \"/\" ) if file ] # Get prefix prefix = directories . pop ( 0 ) if has_prefix else None # Get index try : index = { record . split ( \"_\" )[ 0 ]: record . split ( \"_\" )[ 1 ] for record in directories . pop ( 0 ) . split ( \".\" ) } except IndexError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 except KeyError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 # Recursively get the subindexes subindex = Index . from_filename ( \"/\" . join ( directories )) if len ( directories ) > 0 else None # noqa: E501 return Index ( index , subindex , prefix ) __init__ ( index , subindex = None , prefix = None , size = None ) Index Constructor. Index keys should be all one word lower case. Index values should be UUIDs. Source code in src/index.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self : Self , index : Dict [ str , UUID ], subindex : Index = None , prefix : str = None , size : int = None ) -> None : \"\"\"Index Constructor. Index keys should be all one word lower case. Index values should be UUIDs. \"\"\" self . prefix = prefix self . index = index self . subindex = subindex self . size = size if size else len ( index . keys ()) __str__ () Convert an Index to a string with str() . This will recursively parse the subindexes and include them all in the response. Returns: Name Type Description str str The index object as a string Source code in src/index.py 44 45 46 47 48 49 50 51 52 53 def __str__ ( self : Self ) -> str : \"\"\"Convert an Index to a string with `str()`. This will recursively parse the subindexes and include them all in the response. Returns: str: The index object as a string \"\"\" return json . dumps ( self . to_dict (), sort_keys = True , indent = 4 ) __eq__ ( other_index ) Compare two Index objects with == . Parameters: Name Type Description Default other_index Index The other index to compare required Returns: Name Type Description bool bool Returns true if self == other_index Source code in src/index.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def __eq__ ( self : Self , other_index : Index ) -> bool : \"\"\"Compare two Index objects with `==`. Args: other_index (Index): The other index to compare Returns: bool: Returns true if self == other_index \"\"\" result = \\ self . prefix == other_index . prefix and \\ self . size == other_index . size and \\ self . subindex == other_index . subindex and \\ self . index == other_index . index return result to_dict () Convert the Index object to a dictionary. This will recursively parse the subindexes and include them all in the response. Returns: Name Type Description dict dict The index object as a dict Source code in src/index.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def to_dict ( self : Self ) -> dict : \"\"\"Convert the Index object to a dictionary. This will recursively parse the subindexes and include them all in the response. Returns: dict: The index object as a dict \"\"\" return { \"prefix\" : self . prefix , \"index\" : self . index , \"subindex\" : self . subindex . to_dict () if self . subindex else None } matches ( other_index ) Check if this index has a compatible index with another index. Parameters: Name Type Description Default other_index Index The other index object to compare against required Returns: Name Type Description bool bool Returns false if any self keys are not in the other index or if any values in self are not equal to the corresponding value in the other index Source code in src/index.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def matches ( self : Self , other_index : Index ) -> bool : \"\"\"Check if this index has a compatible index with another index. Args: other_index (Index): The other index object to compare against Returns: bool: Returns false if any self keys are not in the other index or if any values in self are not equal to the corresponding value in the other index \"\"\" for key in self . index : if key not in other_index . index : return False if str ( self . index [ key ]) != str ( other_index . index [ key ]): return False return True is_partial () Check if the index has less keys than expected. Returns: Name Type Description bool bool Returns true if some keys are missing Source code in src/index.py 106 107 108 109 110 111 112 def is_partial ( self : Self ) -> bool : \"\"\"Check if the index has less keys than expected. Returns: bool: Returns true if some keys are missing \"\"\" return self . size != len ( self . index . keys ()) get_metadata () Parse the subindex/filename data. This will recursively parse the subindexes and include them all in the response. Returns: Type Description Dict [ str , UUID ] Dict[str, UUID]: A flat map of (key: value) Source code in src/index.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def get_metadata ( self : Self ) -> Dict [ str , UUID ]: \"\"\"Parse the subindex/filename data. This will recursively parse the subindexes and include them all in the response. Returns: Dict[str, UUID]: A flat map of (key: value) \"\"\" filename = self . get_filename () # recursively get subindex data records = filename . split ( \"/\" ) if self . prefix : records . pop ( 0 ) result = {} for index_level in records : for index in index_level . split ( \".\" ): result [ index . split ( \"_\" )[ 0 ]] = index . split ( \"_\" )[ 1 ] return result get_filename () Convert this object to a filename. Returns: Name Type Description str str The filename for this Index Source code in src/index.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def get_filename ( self : Self ) -> str : \"\"\"Convert this object to a filename. Returns: str: The filename for this Index \"\"\" result = \"\" # Add prefix if self . prefix : result += self . prefix + \"/\" # If not all index keys are known, don't add it to the filename if self . is_partial (): return result # Add current index cur_index = \".\" . join ([ f ' { key } _ { value } ' for key , value in self . index . items () ]) result += cur_index # Recursively add subindexes if self . subindex : result += \"/\" + self . subindex . get_filename () return result from_filename ( filename , has_prefix = False ) staticmethod Convert a filename to an Index object. Parameters: Name Type Description Default filename str The filename to verify required has_prefix bool Does the filename have a prefix? Defaults to False. False Raises: Type Description Exception If the filename is unable to be parsed an exception will be raised Returns: Name Type Description Index Index The index object with data corresponding to the input filename Source code in src/index.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 @staticmethod def from_filename ( filename : str , has_prefix : bool = False ) -> Index : \"\"\"Convert a filename to an Index object. Args: filename (str): The filename to verify has_prefix (bool, optional): Does the filename have a prefix? Defaults to False. Raises: Exception: If the filename is unable to be parsed an exception will be raised Returns: Index: The index object with data corresponding to the input filename \"\"\" directories = [ file for file in filename . split ( \"/\" ) if file ] # Get prefix prefix = directories . pop ( 0 ) if has_prefix else None # Get index try : index = { record . split ( \"_\" )[ 0 ]: record . split ( \"_\" )[ 1 ] for record in directories . pop ( 0 ) . split ( \".\" ) } except IndexError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 except KeyError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 # Recursively get the subindexes subindex = Index . from_filename ( \"/\" . join ( directories )) if len ( directories ) > 0 else None # noqa: E501 return Index ( index , subindex , prefix )","title":"Index"},{"location":"classes_index/#index","text":"","title":"Index"},{"location":"classes_index/#src.index.Index","text":"An object for storing a nested directory structure. Use the Store class to read or write the data for an Index.","title":"Index"},{"location":"classes_index/#src.index.Index--convert-a-filename-to-an-index-object","text":"index = Index.from_filename(\"mydir/show_1/season_2/episode_6.mp4\")","title":"Convert a filename to an Index object"},{"location":"classes_index/#src.index.Index--convert-an-index-object-to-a-filename","text":"filename = index.get_filename() Source code in src/index.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 class Index (): \"\"\"An object for storing a nested directory structure. Use the `Store` class to read or write the data for an Index. ### Convert a filename to an Index object ```py index = Index.from_filename(\"mydir/show_1/season_2/episode_6.mp4\") ``` ### Convert an Index object to a filename ```py filename = index.get_filename() ``` \"\"\" prefix : str index : Dict [ str , UUID ] size : int # number of keys in this index (not including parent or subindex) # noqa: E501 subindex : Index def __init__ ( self : Self , index : Dict [ str , UUID ], subindex : Index = None , prefix : str = None , size : int = None ) -> None : \"\"\"Index Constructor. Index keys should be all one word lower case. Index values should be UUIDs. \"\"\" self . prefix = prefix self . index = index self . subindex = subindex self . size = size if size else len ( index . keys ()) def __str__ ( self : Self ) -> str : \"\"\"Convert an Index to a string with `str()`. This will recursively parse the subindexes and include them all in the response. Returns: str: The index object as a string \"\"\" return json . dumps ( self . to_dict (), sort_keys = True , indent = 4 ) def __eq__ ( self : Self , other_index : Index ) -> bool : \"\"\"Compare two Index objects with `==`. Args: other_index (Index): The other index to compare Returns: bool: Returns true if self == other_index \"\"\" result = \\ self . prefix == other_index . prefix and \\ self . size == other_index . size and \\ self . subindex == other_index . subindex and \\ self . index == other_index . index return result def to_dict ( self : Self ) -> dict : \"\"\"Convert the Index object to a dictionary. This will recursively parse the subindexes and include them all in the response. Returns: dict: The index object as a dict \"\"\" return { \"prefix\" : self . prefix , \"index\" : self . index , \"subindex\" : self . subindex . to_dict () if self . subindex else None } def matches ( self : Self , other_index : Index ) -> bool : \"\"\"Check if this index has a compatible index with another index. Args: other_index (Index): The other index object to compare against Returns: bool: Returns false if any self keys are not in the other index or if any values in self are not equal to the corresponding value in the other index \"\"\" for key in self . index : if key not in other_index . index : return False if str ( self . index [ key ]) != str ( other_index . index [ key ]): return False return True def is_partial ( self : Self ) -> bool : \"\"\"Check if the index has less keys than expected. Returns: bool: Returns true if some keys are missing \"\"\" return self . size != len ( self . index . keys ()) def get_metadata ( self : Self ) -> Dict [ str , UUID ]: \"\"\"Parse the subindex/filename data. This will recursively parse the subindexes and include them all in the response. Returns: Dict[str, UUID]: A flat map of (key: value) \"\"\" filename = self . get_filename () # recursively get subindex data records = filename . split ( \"/\" ) if self . prefix : records . pop ( 0 ) result = {} for index_level in records : for index in index_level . split ( \".\" ): result [ index . split ( \"_\" )[ 0 ]] = index . split ( \"_\" )[ 1 ] return result def get_filename ( self : Self ) -> str : \"\"\"Convert this object to a filename. Returns: str: The filename for this Index \"\"\" result = \"\" # Add prefix if self . prefix : result += self . prefix + \"/\" # If not all index keys are known, don't add it to the filename if self . is_partial (): return result # Add current index cur_index = \".\" . join ([ f ' { key } _ { value } ' for key , value in self . index . items () ]) result += cur_index # Recursively add subindexes if self . subindex : result += \"/\" + self . subindex . get_filename () return result @staticmethod def from_filename ( filename : str , has_prefix : bool = False ) -> Index : \"\"\"Convert a filename to an Index object. Args: filename (str): The filename to verify has_prefix (bool, optional): Does the filename have a prefix? Defaults to False. Raises: Exception: If the filename is unable to be parsed an exception will be raised Returns: Index: The index object with data corresponding to the input filename \"\"\" directories = [ file for file in filename . split ( \"/\" ) if file ] # Get prefix prefix = directories . pop ( 0 ) if has_prefix else None # Get index try : index = { record . split ( \"_\" )[ 0 ]: record . split ( \"_\" )[ 1 ] for record in directories . pop ( 0 ) . split ( \".\" ) } except IndexError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 except KeyError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 # Recursively get the subindexes subindex = Index . from_filename ( \"/\" . join ( directories )) if len ( directories ) > 0 else None # noqa: E501 return Index ( index , subindex , prefix )","title":"Convert an Index object to a filename"},{"location":"classes_index/#src.index.Index.__init__","text":"Index Constructor. Index keys should be all one word lower case. Index values should be UUIDs. Source code in src/index.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self : Self , index : Dict [ str , UUID ], subindex : Index = None , prefix : str = None , size : int = None ) -> None : \"\"\"Index Constructor. Index keys should be all one word lower case. Index values should be UUIDs. \"\"\" self . prefix = prefix self . index = index self . subindex = subindex self . size = size if size else len ( index . keys ())","title":"__init__()"},{"location":"classes_index/#src.index.Index.__str__","text":"Convert an Index to a string with str() . This will recursively parse the subindexes and include them all in the response. Returns: Name Type Description str str The index object as a string Source code in src/index.py 44 45 46 47 48 49 50 51 52 53 def __str__ ( self : Self ) -> str : \"\"\"Convert an Index to a string with `str()`. This will recursively parse the subindexes and include them all in the response. Returns: str: The index object as a string \"\"\" return json . dumps ( self . to_dict (), sort_keys = True , indent = 4 )","title":"__str__()"},{"location":"classes_index/#src.index.Index.__eq__","text":"Compare two Index objects with == . Parameters: Name Type Description Default other_index Index The other index to compare required Returns: Name Type Description bool bool Returns true if self == other_index Source code in src/index.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def __eq__ ( self : Self , other_index : Index ) -> bool : \"\"\"Compare two Index objects with `==`. Args: other_index (Index): The other index to compare Returns: bool: Returns true if self == other_index \"\"\" result = \\ self . prefix == other_index . prefix and \\ self . size == other_index . size and \\ self . subindex == other_index . subindex and \\ self . index == other_index . index return result","title":"__eq__()"},{"location":"classes_index/#src.index.Index.to_dict","text":"Convert the Index object to a dictionary. This will recursively parse the subindexes and include them all in the response. Returns: Name Type Description dict dict The index object as a dict Source code in src/index.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 def to_dict ( self : Self ) -> dict : \"\"\"Convert the Index object to a dictionary. This will recursively parse the subindexes and include them all in the response. Returns: dict: The index object as a dict \"\"\" return { \"prefix\" : self . prefix , \"index\" : self . index , \"subindex\" : self . subindex . to_dict () if self . subindex else None }","title":"to_dict()"},{"location":"classes_index/#src.index.Index.matches","text":"Check if this index has a compatible index with another index. Parameters: Name Type Description Default other_index Index The other index object to compare against required Returns: Name Type Description bool bool Returns false if any self keys are not in the other index or if any values in self are not equal to the corresponding value in the other index Source code in src/index.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def matches ( self : Self , other_index : Index ) -> bool : \"\"\"Check if this index has a compatible index with another index. Args: other_index (Index): The other index object to compare against Returns: bool: Returns false if any self keys are not in the other index or if any values in self are not equal to the corresponding value in the other index \"\"\" for key in self . index : if key not in other_index . index : return False if str ( self . index [ key ]) != str ( other_index . index [ key ]): return False return True","title":"matches()"},{"location":"classes_index/#src.index.Index.is_partial","text":"Check if the index has less keys than expected. Returns: Name Type Description bool bool Returns true if some keys are missing Source code in src/index.py 106 107 108 109 110 111 112 def is_partial ( self : Self ) -> bool : \"\"\"Check if the index has less keys than expected. Returns: bool: Returns true if some keys are missing \"\"\" return self . size != len ( self . index . keys ())","title":"is_partial()"},{"location":"classes_index/#src.index.Index.get_metadata","text":"Parse the subindex/filename data. This will recursively parse the subindexes and include them all in the response. Returns: Type Description Dict [ str , UUID ] Dict[str, UUID]: A flat map of (key: value) Source code in src/index.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def get_metadata ( self : Self ) -> Dict [ str , UUID ]: \"\"\"Parse the subindex/filename data. This will recursively parse the subindexes and include them all in the response. Returns: Dict[str, UUID]: A flat map of (key: value) \"\"\" filename = self . get_filename () # recursively get subindex data records = filename . split ( \"/\" ) if self . prefix : records . pop ( 0 ) result = {} for index_level in records : for index in index_level . split ( \".\" ): result [ index . split ( \"_\" )[ 0 ]] = index . split ( \"_\" )[ 1 ] return result","title":"get_metadata()"},{"location":"classes_index/#src.index.Index.get_filename","text":"Convert this object to a filename. Returns: Name Type Description str str The filename for this Index Source code in src/index.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def get_filename ( self : Self ) -> str : \"\"\"Convert this object to a filename. Returns: str: The filename for this Index \"\"\" result = \"\" # Add prefix if self . prefix : result += self . prefix + \"/\" # If not all index keys are known, don't add it to the filename if self . is_partial (): return result # Add current index cur_index = \".\" . join ([ f ' { key } _ { value } ' for key , value in self . index . items () ]) result += cur_index # Recursively add subindexes if self . subindex : result += \"/\" + self . subindex . get_filename () return result","title":"get_filename()"},{"location":"classes_index/#src.index.Index.from_filename","text":"Convert a filename to an Index object. Parameters: Name Type Description Default filename str The filename to verify required has_prefix bool Does the filename have a prefix? Defaults to False. False Raises: Type Description Exception If the filename is unable to be parsed an exception will be raised Returns: Name Type Description Index Index The index object with data corresponding to the input filename Source code in src/index.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 @staticmethod def from_filename ( filename : str , has_prefix : bool = False ) -> Index : \"\"\"Convert a filename to an Index object. Args: filename (str): The filename to verify has_prefix (bool, optional): Does the filename have a prefix? Defaults to False. Raises: Exception: If the filename is unable to be parsed an exception will be raised Returns: Index: The index object with data corresponding to the input filename \"\"\" directories = [ file for file in filename . split ( \"/\" ) if file ] # Get prefix prefix = directories . pop ( 0 ) if has_prefix else None # Get index try : index = { record . split ( \"_\" )[ 0 ]: record . split ( \"_\" )[ 1 ] for record in directories . pop ( 0 ) . split ( \".\" ) } except IndexError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 except KeyError as e : raise Exception ( f \"Could not parse filename ` { filename } ` with prefix ` { prefix } `\" ) from e # noqa: E501 # Recursively get the subindexes subindex = Index . from_filename ( \"/\" . join ( directories )) if len ( directories ) > 0 else None # noqa: E501 return Index ( index , subindex , prefix )","title":"from_filename()"},{"location":"classes_ipfs/","text":"Ipfs src.ipfs.Ipfs dataclass IPFS Python Client. This client uses the ipfs rpc via http. The ipfs server or gateway is specified in the constructor. Usage For testing with a local ipfs node import ipfs client = ipfs.Ipfs() # defaults to http://127.0.0.1:5001/api/v0 client.mkdir(\"my_dir\") client.add(\"my_dir/my_file\", b\"my_contents\") References IPFS RPC documentation https://docs.ipfs.tech/reference/kubo/rpc/#api-v0-files-write For more information about ipfs https://docs.ipfs.tech/concepts/what-is-ipfs/#defining-ipfs Source code in src/ipfs.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 @dataclass class Ipfs (): \"\"\"IPFS Python Client. This client uses the ipfs rpc via http. The ipfs server or gateway is specified in the constructor. ### Usage For testing with a local ipfs node ```py import ipfs client = ipfs.Ipfs() # defaults to http://127.0.0.1:5001/api/v0 client.mkdir(\"my_dir\") client.add(\"my_dir/my_file\", b\"my_contents\") ``` ### References IPFS RPC documentation: https://docs.ipfs.tech/reference/kubo/rpc/#api-v0-files-write For more information about ipfs: https://docs.ipfs.tech/concepts/what-is-ipfs/#defining-ipfs \"\"\" host : str port : int version : str def __init__ ( self : Self , host : str = \"http://127.0.0.1\" , port : int = 5001 , version : str = \"v0\" ) -> None : \"\"\"Create an IPFS client. Args: host (str, optional): IPFS server host or gateway host. Defaults to \"http://127.0.0.1\". # noqa: E501 port (int, optional): IPFS port. Defaults to 5001. version (str, optional): IPFS rpc version. Defaults to \"v0\". \"\"\" self . host = host self . port = port self . version = version def _make_request ( self : Self , endpoint : str , params : dict = None , files : dict = None , raise_for_status : bool = True ) -> bytes : \"\"\"Make an http request for an IPFS RPC call. Args: endpoint (str): The IPFS RPC endpoint params (dict, optional): The RPC params. Defaults to None. files (dict, optional): The RPC files. Defaults to None. raise_for_status (bool, optional): If true, raise any exceptions that are caught. Defaults to True. Returns: bytes: The http response data \"\"\" url = f \" { self . host } : { self . port } /api/ { self . version } / { endpoint } \" response = requests . post ( url , params = params , files = files ) if raise_for_status : response . raise_for_status () return response . content def _dag_put ( self : Self , data : bytes ) -> str : \"\"\"Call the dag/put endpoint. Args: data (bytes): The raw object data Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/put\" , params = { \"store-codec\" : \"raw\" , \"input-codec\" : \"raw\" }, files = { \"object data\" : add_prefix ( 'raw' , data ) }, raise_for_status = False ) result = json . loads ( response . decode ()) return result [ \"Cid\" ][ \"/\" ] except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def _dag_get ( self : Self , filename : str ) -> str : \"\"\"Call the dag/get endpoint. Args: filename (str): The filename to get the dag for Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/get\" , params = { \"arg\" : filename , # \"output-codec\": \"raw\" }, raise_for_status = False ) return json . loads ( response . decode ()) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def mkdir ( self : Self , directory_name : str , with_home : bool = True ) -> None : \"\"\"Create a directory in ipfs. Args: directory_name (str): The name of the directory to create with_home (bool, optional): If true, include Ipfs.IPFS_HOME as a directory prefix. Defaults to True. Raises: RuntimeError: An exception is raised for any RPC errors \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( directory_name ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) path = f \" { IPFS_HOME } / { directory_name } \" if with_home else f \"/ { directory_name } \" # noqa: E501 try : self . _make_request ( endpoint = \"files/mkdir\" , params = { \"arg\" : path }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def read ( self : Self , filename : str ) -> bytes : \"\"\"Read a file from ipfs. Args: filename (str): The file to read Returns: (bytes): The file contents \"\"\" try : return self . _make_request ( endpoint = \"files/read\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def write ( self : Self , filename : str , data : bytes ) -> None : \"\"\"Overwrite file contents in ipfs. Args: filename (str): The filename to write to data (bytes): The data to write Raises: NotImplementedError: This function is not implemented. For now, just use `add` and `delete` \"\"\" raise NotImplementedError ( \"For now, just use `add` and `delete`\" ) try : stat = self . stat ( filename ) dag = self . _dag_get ( stat [ \"Hash\" ]) # print(dag) # print(dag[\"/\"][\"bytes\"].encode) example = Example () example . ParseFromString ( dag ) self . _make_request ( endpoint = \"files/write\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" , \"truncate\" : True , \"raw-leaves\" : True }, files = { 'file' : example . SerializeToString () } ) except requests . exceptions . HTTPError as e : raise RuntimeError ( e . response . _content . decode ()) from e def add ( self : Self , filename : str , data : bytes ) -> None : \"\"\"Create a new file in ipfs. This does not work for updating existing files. Args: filename (str): The filename for the uploaded data data (bytes): The data that will be written to the new file \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( filename ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) try : self . _make_request ( endpoint = \"add\" , params = { \"to-files\" : f \" { IPFS_HOME } / { filename } \" , \"raw-leaves\" : True }, files = { 'file' : data } ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def does_file_exist ( self : Self , filename : str ) -> bool : \"\"\"Check if a file exists in ipfs. Args: filename (str): The file to check Returns: bool: True if the file exists, false otherwise \"\"\" try : response = self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False ) return 'file does not exist' not in response . decode () except Exception as e : print ( e ) if 'file does not exist' in e . response . _content . decode (): return False raise RuntimeError ( e . response . _content . decode ()) from e def stat ( self : Self , filename : str ) -> bytes : \"\"\"Call the files/stat endpoint. Args: filename (str): The path to search on ipfs Returns: bytes: The RPC response \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def list_files ( self : Self , prefix : str = \"\" ) -> List [ str ]: \"\"\"List the ipfs files in a directory. Args: prefix (str): The path to search on ipfs Returns: List[str]: The list of filenames found at that location \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/ls\" , params = { \"arg\" : f \" { IPFS_HOME } / { prefix } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def delete ( self : Self , filename : str ) -> None : \"\"\"Delete a file from ipfs. Args: filename (str): The filename to delete \"\"\" try : self . _make_request ( endpoint = \"files/rm\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" , \"recursive\" : True }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e __init__ ( host = 'http://127.0.0.1' , port = 5001 , version = 'v0' ) Create an IPFS client. Parameters: Name Type Description Default host str IPFS server host or gateway host. Defaults to \"http://127.0.0.1\". # noqa: E501 'http://127.0.0.1' port int IPFS port. Defaults to 5001. 5001 version str IPFS rpc version. Defaults to \"v0\". 'v0' Source code in src/ipfs.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def __init__ ( self : Self , host : str = \"http://127.0.0.1\" , port : int = 5001 , version : str = \"v0\" ) -> None : \"\"\"Create an IPFS client. Args: host (str, optional): IPFS server host or gateway host. Defaults to \"http://127.0.0.1\". # noqa: E501 port (int, optional): IPFS port. Defaults to 5001. version (str, optional): IPFS rpc version. Defaults to \"v0\". \"\"\" self . host = host self . port = port self . version = version _make_request ( endpoint , params = None , files = None , raise_for_status = True ) Make an http request for an IPFS RPC call. Parameters: Name Type Description Default endpoint str The IPFS RPC endpoint required params dict The RPC params. Defaults to None. None files dict The RPC files. Defaults to None. None raise_for_status bool If true, raise any exceptions that are caught. Defaults to True. True Returns: Name Type Description bytes bytes The http response data Source code in src/ipfs.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def _make_request ( self : Self , endpoint : str , params : dict = None , files : dict = None , raise_for_status : bool = True ) -> bytes : \"\"\"Make an http request for an IPFS RPC call. Args: endpoint (str): The IPFS RPC endpoint params (dict, optional): The RPC params. Defaults to None. files (dict, optional): The RPC files. Defaults to None. raise_for_status (bool, optional): If true, raise any exceptions that are caught. Defaults to True. Returns: bytes: The http response data \"\"\" url = f \" { self . host } : { self . port } /api/ { self . version } / { endpoint } \" response = requests . post ( url , params = params , files = files ) if raise_for_status : response . raise_for_status () return response . content _dag_put ( data ) Call the dag/put endpoint. Parameters: Name Type Description Default data bytes The raw object data required Raises: Type Description RuntimeError An exception is raised for any RPC errors Returns: Name Type Description str str The RPC response Source code in src/ipfs.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def _dag_put ( self : Self , data : bytes ) -> str : \"\"\"Call the dag/put endpoint. Args: data (bytes): The raw object data Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/put\" , params = { \"store-codec\" : \"raw\" , \"input-codec\" : \"raw\" }, files = { \"object data\" : add_prefix ( 'raw' , data ) }, raise_for_status = False ) result = json . loads ( response . decode ()) return result [ \"Cid\" ][ \"/\" ] except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e _dag_get ( filename ) Call the dag/get endpoint. Parameters: Name Type Description Default filename str The filename to get the dag for required Raises: Type Description RuntimeError An exception is raised for any RPC errors Returns: Name Type Description str str The RPC response Source code in src/ipfs.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def _dag_get ( self : Self , filename : str ) -> str : \"\"\"Call the dag/get endpoint. Args: filename (str): The filename to get the dag for Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/get\" , params = { \"arg\" : filename , # \"output-codec\": \"raw\" }, raise_for_status = False ) return json . loads ( response . decode ()) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e mkdir ( directory_name , with_home = True ) Create a directory in ipfs. Parameters: Name Type Description Default directory_name str The name of the directory to create required with_home bool If true, include Ipfs.IPFS_HOME as a directory prefix. Defaults to True. True Raises: Type Description RuntimeError An exception is raised for any RPC errors Source code in src/ipfs.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def mkdir ( self : Self , directory_name : str , with_home : bool = True ) -> None : \"\"\"Create a directory in ipfs. Args: directory_name (str): The name of the directory to create with_home (bool, optional): If true, include Ipfs.IPFS_HOME as a directory prefix. Defaults to True. Raises: RuntimeError: An exception is raised for any RPC errors \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( directory_name ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) path = f \" { IPFS_HOME } / { directory_name } \" if with_home else f \"/ { directory_name } \" # noqa: E501 try : self . _make_request ( endpoint = \"files/mkdir\" , params = { \"arg\" : path }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e read ( filename ) Read a file from ipfs. Parameters: Name Type Description Default filename str The file to read required Returns: Type Description bytes The file contents Source code in src/ipfs.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def read ( self : Self , filename : str ) -> bytes : \"\"\"Read a file from ipfs. Args: filename (str): The file to read Returns: (bytes): The file contents \"\"\" try : return self . _make_request ( endpoint = \"files/read\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e add ( filename , data ) Create a new file in ipfs. This does not work for updating existing files. Parameters: Name Type Description Default filename str The filename for the uploaded data required data bytes The data that will be written to the new file required Source code in src/ipfs.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 def add ( self : Self , filename : str , data : bytes ) -> None : \"\"\"Create a new file in ipfs. This does not work for updating existing files. Args: filename (str): The filename for the uploaded data data (bytes): The data that will be written to the new file \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( filename ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) try : self . _make_request ( endpoint = \"add\" , params = { \"to-files\" : f \" { IPFS_HOME } / { filename } \" , \"raw-leaves\" : True }, files = { 'file' : data } ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e does_file_exist ( filename ) Check if a file exists in ipfs. Parameters: Name Type Description Default filename str The file to check required Returns: Name Type Description bool bool True if the file exists, false otherwise Source code in src/ipfs.py 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 def does_file_exist ( self : Self , filename : str ) -> bool : \"\"\"Check if a file exists in ipfs. Args: filename (str): The file to check Returns: bool: True if the file exists, false otherwise \"\"\" try : response = self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False ) return 'file does not exist' not in response . decode () except Exception as e : print ( e ) if 'file does not exist' in e . response . _content . decode (): return False raise RuntimeError ( e . response . _content . decode ()) from e stat ( filename ) Call the files/stat endpoint. Parameters: Name Type Description Default filename str The path to search on ipfs required Returns: Name Type Description bytes bytes The RPC response Source code in src/ipfs.py 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 def stat ( self : Self , filename : str ) -> bytes : \"\"\"Call the files/stat endpoint. Args: filename (str): The path to search on ipfs Returns: bytes: The RPC response \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e list_files ( prefix = '' ) List the ipfs files in a directory. Parameters: Name Type Description Default prefix str The path to search on ipfs '' Returns: Type Description List [ str ] List[str]: The list of filenames found at that location Source code in src/ipfs.py 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 def list_files ( self : Self , prefix : str = \"\" ) -> List [ str ]: \"\"\"List the ipfs files in a directory. Args: prefix (str): The path to search on ipfs Returns: List[str]: The list of filenames found at that location \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/ls\" , params = { \"arg\" : f \" { IPFS_HOME } / { prefix } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e delete ( filename ) Delete a file from ipfs. Parameters: Name Type Description Default filename str The filename to delete required Source code in src/ipfs.py 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 def delete ( self : Self , filename : str ) -> None : \"\"\"Delete a file from ipfs. Args: filename (str): The filename to delete \"\"\" try : self . _make_request ( endpoint = \"files/rm\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" , \"recursive\" : True }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"Ipfs"},{"location":"classes_ipfs/#ipfs","text":"","title":"Ipfs"},{"location":"classes_ipfs/#src.ipfs.Ipfs","text":"IPFS Python Client. This client uses the ipfs rpc via http. The ipfs server or gateway is specified in the constructor.","title":"Ipfs"},{"location":"classes_ipfs/#src.ipfs.Ipfs--usage","text":"For testing with a local ipfs node import ipfs client = ipfs.Ipfs() # defaults to http://127.0.0.1:5001/api/v0 client.mkdir(\"my_dir\") client.add(\"my_dir/my_file\", b\"my_contents\")","title":"Usage"},{"location":"classes_ipfs/#src.ipfs.Ipfs--references","text":"IPFS RPC documentation https://docs.ipfs.tech/reference/kubo/rpc/#api-v0-files-write For more information about ipfs https://docs.ipfs.tech/concepts/what-is-ipfs/#defining-ipfs Source code in src/ipfs.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 @dataclass class Ipfs (): \"\"\"IPFS Python Client. This client uses the ipfs rpc via http. The ipfs server or gateway is specified in the constructor. ### Usage For testing with a local ipfs node ```py import ipfs client = ipfs.Ipfs() # defaults to http://127.0.0.1:5001/api/v0 client.mkdir(\"my_dir\") client.add(\"my_dir/my_file\", b\"my_contents\") ``` ### References IPFS RPC documentation: https://docs.ipfs.tech/reference/kubo/rpc/#api-v0-files-write For more information about ipfs: https://docs.ipfs.tech/concepts/what-is-ipfs/#defining-ipfs \"\"\" host : str port : int version : str def __init__ ( self : Self , host : str = \"http://127.0.0.1\" , port : int = 5001 , version : str = \"v0\" ) -> None : \"\"\"Create an IPFS client. Args: host (str, optional): IPFS server host or gateway host. Defaults to \"http://127.0.0.1\". # noqa: E501 port (int, optional): IPFS port. Defaults to 5001. version (str, optional): IPFS rpc version. Defaults to \"v0\". \"\"\" self . host = host self . port = port self . version = version def _make_request ( self : Self , endpoint : str , params : dict = None , files : dict = None , raise_for_status : bool = True ) -> bytes : \"\"\"Make an http request for an IPFS RPC call. Args: endpoint (str): The IPFS RPC endpoint params (dict, optional): The RPC params. Defaults to None. files (dict, optional): The RPC files. Defaults to None. raise_for_status (bool, optional): If true, raise any exceptions that are caught. Defaults to True. Returns: bytes: The http response data \"\"\" url = f \" { self . host } : { self . port } /api/ { self . version } / { endpoint } \" response = requests . post ( url , params = params , files = files ) if raise_for_status : response . raise_for_status () return response . content def _dag_put ( self : Self , data : bytes ) -> str : \"\"\"Call the dag/put endpoint. Args: data (bytes): The raw object data Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/put\" , params = { \"store-codec\" : \"raw\" , \"input-codec\" : \"raw\" }, files = { \"object data\" : add_prefix ( 'raw' , data ) }, raise_for_status = False ) result = json . loads ( response . decode ()) return result [ \"Cid\" ][ \"/\" ] except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def _dag_get ( self : Self , filename : str ) -> str : \"\"\"Call the dag/get endpoint. Args: filename (str): The filename to get the dag for Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/get\" , params = { \"arg\" : filename , # \"output-codec\": \"raw\" }, raise_for_status = False ) return json . loads ( response . decode ()) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def mkdir ( self : Self , directory_name : str , with_home : bool = True ) -> None : \"\"\"Create a directory in ipfs. Args: directory_name (str): The name of the directory to create with_home (bool, optional): If true, include Ipfs.IPFS_HOME as a directory prefix. Defaults to True. Raises: RuntimeError: An exception is raised for any RPC errors \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( directory_name ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) path = f \" { IPFS_HOME } / { directory_name } \" if with_home else f \"/ { directory_name } \" # noqa: E501 try : self . _make_request ( endpoint = \"files/mkdir\" , params = { \"arg\" : path }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def read ( self : Self , filename : str ) -> bytes : \"\"\"Read a file from ipfs. Args: filename (str): The file to read Returns: (bytes): The file contents \"\"\" try : return self . _make_request ( endpoint = \"files/read\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def write ( self : Self , filename : str , data : bytes ) -> None : \"\"\"Overwrite file contents in ipfs. Args: filename (str): The filename to write to data (bytes): The data to write Raises: NotImplementedError: This function is not implemented. For now, just use `add` and `delete` \"\"\" raise NotImplementedError ( \"For now, just use `add` and `delete`\" ) try : stat = self . stat ( filename ) dag = self . _dag_get ( stat [ \"Hash\" ]) # print(dag) # print(dag[\"/\"][\"bytes\"].encode) example = Example () example . ParseFromString ( dag ) self . _make_request ( endpoint = \"files/write\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" , \"truncate\" : True , \"raw-leaves\" : True }, files = { 'file' : example . SerializeToString () } ) except requests . exceptions . HTTPError as e : raise RuntimeError ( e . response . _content . decode ()) from e def add ( self : Self , filename : str , data : bytes ) -> None : \"\"\"Create a new file in ipfs. This does not work for updating existing files. Args: filename (str): The filename for the uploaded data data (bytes): The data that will be written to the new file \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( filename ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) try : self . _make_request ( endpoint = \"add\" , params = { \"to-files\" : f \" { IPFS_HOME } / { filename } \" , \"raw-leaves\" : True }, files = { 'file' : data } ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def does_file_exist ( self : Self , filename : str ) -> bool : \"\"\"Check if a file exists in ipfs. Args: filename (str): The file to check Returns: bool: True if the file exists, false otherwise \"\"\" try : response = self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False ) return 'file does not exist' not in response . decode () except Exception as e : print ( e ) if 'file does not exist' in e . response . _content . decode (): return False raise RuntimeError ( e . response . _content . decode ()) from e def stat ( self : Self , filename : str ) -> bytes : \"\"\"Call the files/stat endpoint. Args: filename (str): The path to search on ipfs Returns: bytes: The RPC response \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def list_files ( self : Self , prefix : str = \"\" ) -> List [ str ]: \"\"\"List the ipfs files in a directory. Args: prefix (str): The path to search on ipfs Returns: List[str]: The list of filenames found at that location \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/ls\" , params = { \"arg\" : f \" { IPFS_HOME } / { prefix } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e def delete ( self : Self , filename : str ) -> None : \"\"\"Delete a file from ipfs. Args: filename (str): The filename to delete \"\"\" try : self . _make_request ( endpoint = \"files/rm\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" , \"recursive\" : True }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"References"},{"location":"classes_ipfs/#src.ipfs.Ipfs.__init__","text":"Create an IPFS client. Parameters: Name Type Description Default host str IPFS server host or gateway host. Defaults to \"http://127.0.0.1\". # noqa: E501 'http://127.0.0.1' port int IPFS port. Defaults to 5001. 5001 version str IPFS rpc version. Defaults to \"v0\". 'v0' Source code in src/ipfs.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def __init__ ( self : Self , host : str = \"http://127.0.0.1\" , port : int = 5001 , version : str = \"v0\" ) -> None : \"\"\"Create an IPFS client. Args: host (str, optional): IPFS server host or gateway host. Defaults to \"http://127.0.0.1\". # noqa: E501 port (int, optional): IPFS port. Defaults to 5001. version (str, optional): IPFS rpc version. Defaults to \"v0\". \"\"\" self . host = host self . port = port self . version = version","title":"__init__()"},{"location":"classes_ipfs/#src.ipfs.Ipfs._make_request","text":"Make an http request for an IPFS RPC call. Parameters: Name Type Description Default endpoint str The IPFS RPC endpoint required params dict The RPC params. Defaults to None. None files dict The RPC files. Defaults to None. None raise_for_status bool If true, raise any exceptions that are caught. Defaults to True. True Returns: Name Type Description bytes bytes The http response data Source code in src/ipfs.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def _make_request ( self : Self , endpoint : str , params : dict = None , files : dict = None , raise_for_status : bool = True ) -> bytes : \"\"\"Make an http request for an IPFS RPC call. Args: endpoint (str): The IPFS RPC endpoint params (dict, optional): The RPC params. Defaults to None. files (dict, optional): The RPC files. Defaults to None. raise_for_status (bool, optional): If true, raise any exceptions that are caught. Defaults to True. Returns: bytes: The http response data \"\"\" url = f \" { self . host } : { self . port } /api/ { self . version } / { endpoint } \" response = requests . post ( url , params = params , files = files ) if raise_for_status : response . raise_for_status () return response . content","title":"_make_request()"},{"location":"classes_ipfs/#src.ipfs.Ipfs._dag_put","text":"Call the dag/put endpoint. Parameters: Name Type Description Default data bytes The raw object data required Raises: Type Description RuntimeError An exception is raised for any RPC errors Returns: Name Type Description str str The RPC response Source code in src/ipfs.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def _dag_put ( self : Self , data : bytes ) -> str : \"\"\"Call the dag/put endpoint. Args: data (bytes): The raw object data Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/put\" , params = { \"store-codec\" : \"raw\" , \"input-codec\" : \"raw\" }, files = { \"object data\" : add_prefix ( 'raw' , data ) }, raise_for_status = False ) result = json . loads ( response . decode ()) return result [ \"Cid\" ][ \"/\" ] except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"_dag_put()"},{"location":"classes_ipfs/#src.ipfs.Ipfs._dag_get","text":"Call the dag/get endpoint. Parameters: Name Type Description Default filename str The filename to get the dag for required Raises: Type Description RuntimeError An exception is raised for any RPC errors Returns: Name Type Description str str The RPC response Source code in src/ipfs.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 def _dag_get ( self : Self , filename : str ) -> str : \"\"\"Call the dag/get endpoint. Args: filename (str): The filename to get the dag for Raises: RuntimeError: An exception is raised for any RPC errors Returns: str: The RPC response \"\"\" try : response = self . _make_request ( endpoint = \"dag/get\" , params = { \"arg\" : filename , # \"output-codec\": \"raw\" }, raise_for_status = False ) return json . loads ( response . decode ()) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"_dag_get()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.mkdir","text":"Create a directory in ipfs. Parameters: Name Type Description Default directory_name str The name of the directory to create required with_home bool If true, include Ipfs.IPFS_HOME as a directory prefix. Defaults to True. True Raises: Type Description RuntimeError An exception is raised for any RPC errors Source code in src/ipfs.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def mkdir ( self : Self , directory_name : str , with_home : bool = True ) -> None : \"\"\"Create a directory in ipfs. Args: directory_name (str): The name of the directory to create with_home (bool, optional): If true, include Ipfs.IPFS_HOME as a directory prefix. Defaults to True. Raises: RuntimeError: An exception is raised for any RPC errors \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( directory_name ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) path = f \" { IPFS_HOME } / { directory_name } \" if with_home else f \"/ { directory_name } \" # noqa: E501 try : self . _make_request ( endpoint = \"files/mkdir\" , params = { \"arg\" : path }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"mkdir()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.read","text":"Read a file from ipfs. Parameters: Name Type Description Default filename str The file to read required Returns: Type Description bytes The file contents Source code in src/ipfs.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def read ( self : Self , filename : str ) -> bytes : \"\"\"Read a file from ipfs. Args: filename (str): The file to read Returns: (bytes): The file contents \"\"\" try : return self . _make_request ( endpoint = \"files/read\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"read()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.add","text":"Create a new file in ipfs. This does not work for updating existing files. Parameters: Name Type Description Default filename str The filename for the uploaded data required data bytes The data that will be written to the new file required Source code in src/ipfs.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 def add ( self : Self , filename : str , data : bytes ) -> None : \"\"\"Create a new file in ipfs. This does not work for updating existing files. Args: filename (str): The filename for the uploaded data data (bytes): The data that will be written to the new file \"\"\" # Split the filename into its directory and basename components parts = os . path . split ( filename ) # If the directory part is not empty, create it recursively if parts [ 0 ]: self . mkdir ( parts [ 0 ]) try : self . _make_request ( endpoint = \"add\" , params = { \"to-files\" : f \" { IPFS_HOME } / { filename } \" , \"raw-leaves\" : True }, files = { 'file' : data } ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"add()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.does_file_exist","text":"Check if a file exists in ipfs. Parameters: Name Type Description Default filename str The file to check required Returns: Name Type Description bool bool True if the file exists, false otherwise Source code in src/ipfs.py 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 def does_file_exist ( self : Self , filename : str ) -> bool : \"\"\"Check if a file exists in ipfs. Args: filename (str): The file to check Returns: bool: True if the file exists, false otherwise \"\"\" try : response = self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False ) return 'file does not exist' not in response . decode () except Exception as e : print ( e ) if 'file does not exist' in e . response . _content . decode (): return False raise RuntimeError ( e . response . _content . decode ()) from e","title":"does_file_exist()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.stat","text":"Call the files/stat endpoint. Parameters: Name Type Description Default filename str The path to search on ipfs required Returns: Name Type Description bytes bytes The RPC response Source code in src/ipfs.py 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 def stat ( self : Self , filename : str ) -> bytes : \"\"\"Call the files/stat endpoint. Args: filename (str): The path to search on ipfs Returns: bytes: The RPC response \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/stat\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"stat()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.list_files","text":"List the ipfs files in a directory. Parameters: Name Type Description Default prefix str The path to search on ipfs '' Returns: Type Description List [ str ] List[str]: The list of filenames found at that location Source code in src/ipfs.py 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 def list_files ( self : Self , prefix : str = \"\" ) -> List [ str ]: \"\"\"List the ipfs files in a directory. Args: prefix (str): The path to search on ipfs Returns: List[str]: The list of filenames found at that location \"\"\" try : return json . loads ( self . _make_request ( endpoint = \"files/ls\" , params = { \"arg\" : f \" { IPFS_HOME } / { prefix } \" }, raise_for_status = False )) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"list_files()"},{"location":"classes_ipfs/#src.ipfs.Ipfs.delete","text":"Delete a file from ipfs. Parameters: Name Type Description Default filename str The filename to delete required Source code in src/ipfs.py 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 def delete ( self : Self , filename : str ) -> None : \"\"\"Delete a file from ipfs. Args: filename (str): The filename to delete \"\"\" try : self . _make_request ( endpoint = \"files/rm\" , params = { \"arg\" : f \" { IPFS_HOME } / { filename } \" , \"recursive\" : True }, raise_for_status = False ) except Exception as e : print ( e ) raise RuntimeError ( e . response . _content . decode ()) from e","title":"delete()"},{"location":"classes_store/","text":"Store src.store.Store dataclass A utility to read/write protobuf data to ipfs. Reading: from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), reader=MyProtobuf() ) store.read() print(store.reader) Writing: from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), writer=MyProtobuf() ) store.add() Write with multiple indexes. Create a tiered file structure based on IDs. \u251c\u2500\u2500 fashion/ \u251c\u2500\u2500 designer_1.manufacturer_1 \u251c\u2500\u2500 designer_2.manufacturer_1 \u251c\u2500\u2500 deal_16.data \u251c\u2500\u2500 designer_4.manufacturer_3 \u251c\u2500\u2500 deal_1.data \u251c\u2500\u2500 deal_2.data from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal index = Index( prefix=\"fashion\", index={ \"designer\": str(uuid.uuid4()), \"manufacturer\": str(uuid.uuid4()) }, subindex=Index( index={ \"deal\": str(uuid.uuid4()) } ) ) data = Deal(type=Type.BUZZ, content=\"fizz\") store = Store(index=index, ipfs=Ipfs(), writer=data) store.add() Query the multiple indexes: Ex: get all deals with designer id \"123\" from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal query_index = Index( prefix=\"fashion\", index={ \"designer\": \"123\" } ) reader = Deal() store = Store.query(query_index, ipfs, reader) print(reader) Source code in src/store.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 @dataclass class Store (): \"\"\"A utility to read/write protobuf data to ipfs. Reading: ```py from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), reader=MyProtobuf() ) store.read() print(store.reader) ``` Writing: ```py from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), writer=MyProtobuf() ) store.add() ``` Write with multiple indexes. Create a tiered file structure based on IDs. ``` \u251c\u2500\u2500 fashion/ \u251c\u2500\u2500 designer_1.manufacturer_1 \u251c\u2500\u2500 designer_2.manufacturer_1 \u251c\u2500\u2500 deal_16.data \u251c\u2500\u2500 designer_4.manufacturer_3 \u251c\u2500\u2500 deal_1.data \u251c\u2500\u2500 deal_2.data ``` ```py from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal index = Index( prefix=\"fashion\", index={ \"designer\": str(uuid.uuid4()), \"manufacturer\": str(uuid.uuid4()) }, subindex=Index( index={ \"deal\": str(uuid.uuid4()) } ) ) data = Deal(type=Type.BUZZ, content=\"fizz\") store = Store(index=index, ipfs=Ipfs(), writer=data) store.add() ``` Query the multiple indexes: Ex: get all deals with designer id \"123\" ```py from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal query_index = Index( prefix=\"fashion\", index={ \"designer\": \"123\" } ) reader = Deal() store = Store.query(query_index, ipfs, reader) print(reader) ``` \"\"\" index : Index writer : Message reader : Message def __init__ ( self : Self , index : Index , ipfs : Ipfs , writer : Message = None , reader : Message = None ) -> None : \"\"\"Construct a Store object. Args: index (Index): An object representing the filepath ipfs (Ipfs): The IPFS client writer (Message, optional): The protobuf object with the data to write to ipfs on `.write()`. Defaults to None. reader (Message, optional): The protobuf object to populate when reading the data from ipfs with `.read()`. Defaults to None. \"\"\" self . index = index self . ipfs = ipfs self . writer = writer self . reader = reader def read ( self : Self ) -> None : \"\"\"Read the data from ipfs into `self.reader`. Raises: FileNotFoundError: An exception is raised if the file is not found on IPFS. \"\"\" filename = self . index . get_filename () result = self . ipfs . read ( filename ) if not result : raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), filename ) self . reader . ParseFromString ( result ) def write ( self : Self ) -> None : \"\"\"Write the protobuf data from `self.writer` to IPFS.\"\"\" raise NotImplementedError ( \"For now, just use `add` and `delete`\" ) self . ipfs . write ( self . index . get_filename (), self . writer . SerializeToString () ) def add ( self : Self ) -> None : \"\"\"Add the protobuf data from `self.writer` to IPFS.\"\"\" self . ipfs . add ( self . index . get_filename (), self . writer . SerializeToString () ) def delete ( self : Self ) -> None : \"\"\"Only needed for local testing.\"\"\" self . ipfs . delete ( self . index . get_filename ()) @staticmethod def to_dataframe ( data : List [ Store ], protobuf_parsers : Dict [ str , FunctionType ]) -> pd . DataFrame : \"\"\"Convert a list of Store objects to a pandas dataframe. The data for each Store must be read into memory beforehand; using `store.read()` Args: data (List[Store]): The list of Store objects with Indexes protobuf_parsers: (Dict[str, function]): key, value pair of key (str) --> pandas column name value (function) --> how to extract the value from the store The function should accept a Store object and return Any Returns: pd.DataFrame: The index and subindex data reformatted into a dataframe \"\"\" pandas_input = {} for store in data : # add metadata metadata = store . index . get_metadata () for key in metadata : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( metadata [ key ]) # add top level data from the reader for key in protobuf_parsers : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( protobuf_parsers [ key ]( store )) # load the data into a pandas dataframe return pd . DataFrame . from_dict ( pandas_input ) @staticmethod def query_indexes ( query_index : Index , ipfs : Ipfs ) -> List [ Index ]: \"\"\"Query ipfs based on the `query_index` param. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. Returns: List[Index]: The matching filenames found in ipfs, loaded into a list of Index objects \"\"\" result = [] # list the files in the directory path = query_index . get_filename () response = ipfs . list_files ( path ) filenames = [ file [ 'Name' ] for file in response [ 'Entries' ]] for filename in filenames : # Listing the same file twice indicates the base case # ex: # path = `ls dir1/dir2` --> filenames = [\"filename\"] # path = `ls dir1/dir2/filename` --> filenames = [\"filename\"] if filename in path : return [ query_index ] # filter filenames based on the index full_filename = f \" { path } / { filename } \" . replace ( \"//\" , \"/\" ) from_index = Index . from_filename ( filename = full_filename , has_prefix = query_index . prefix ) if query_index . matches ( from_index ): result += Store . query_indexes ( from_index , ipfs ) return result @staticmethod def query ( query_index : Index , ipfs : Ipfs , reader : Message ) -> Iterator [ Store ]: \"\"\"Query ipfs based on the `query_index` param. Find the filenames matching the query_index. Read the file contents from ipfs for each matching filename. Parse the file contents into the reader protobuf object. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. reader (Message): _description_ Yields: Iterator[Store]: The list of matching Store objects with file content loaded into the `reader` attribute \"\"\" for response_index in Store . query_indexes ( query_index , ipfs ): store = Store ( index = response_index , reader = reader , ipfs = ipfs ) store . read () yield store __init__ ( index , ipfs , writer = None , reader = None ) Construct a Store object. Parameters: Name Type Description Default index Index An object representing the filepath required ipfs Ipfs The IPFS client required writer Message The protobuf object with the data to write to ipfs on .write() . Defaults to None. None reader Message The protobuf object to populate when reading the data from ipfs with .read() . Defaults to None. None Source code in src/store.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __init__ ( self : Self , index : Index , ipfs : Ipfs , writer : Message = None , reader : Message = None ) -> None : \"\"\"Construct a Store object. Args: index (Index): An object representing the filepath ipfs (Ipfs): The IPFS client writer (Message, optional): The protobuf object with the data to write to ipfs on `.write()`. Defaults to None. reader (Message, optional): The protobuf object to populate when reading the data from ipfs with `.read()`. Defaults to None. \"\"\" self . index = index self . ipfs = ipfs self . writer = writer self . reader = reader read () Read the data from ipfs into self.reader . Raises: Type Description FileNotFoundError An exception is raised if the file is not found on IPFS. Source code in src/store.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def read ( self : Self ) -> None : \"\"\"Read the data from ipfs into `self.reader`. Raises: FileNotFoundError: An exception is raised if the file is not found on IPFS. \"\"\" filename = self . index . get_filename () result = self . ipfs . read ( filename ) if not result : raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), filename ) self . reader . ParseFromString ( result ) add () Add the protobuf data from self.writer to IPFS. Source code in src/store.py 149 150 151 152 153 154 def add ( self : Self ) -> None : \"\"\"Add the protobuf data from `self.writer` to IPFS.\"\"\" self . ipfs . add ( self . index . get_filename (), self . writer . SerializeToString () ) delete () Only needed for local testing. Source code in src/store.py 156 157 158 def delete ( self : Self ) -> None : \"\"\"Only needed for local testing.\"\"\" self . ipfs . delete ( self . index . get_filename ()) to_dataframe ( data , protobuf_parsers ) staticmethod Convert a list of Store objects to a pandas dataframe. The data for each Store must be read into memory beforehand; using store.read() Parameters: Name Type Description Default data List [ Store ] The list of Store objects with Indexes required protobuf_parsers Dict [ str , FunctionType ] (Dict[str, function]): key, value pair of key (str) --> pandas column name value (function) --> how to extract the value from the store The function should accept a Store object and return Any required Returns: Type Description pd . DataFrame pd.DataFrame: The index and subindex data reformatted into a dataframe Source code in src/store.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @staticmethod def to_dataframe ( data : List [ Store ], protobuf_parsers : Dict [ str , FunctionType ]) -> pd . DataFrame : \"\"\"Convert a list of Store objects to a pandas dataframe. The data for each Store must be read into memory beforehand; using `store.read()` Args: data (List[Store]): The list of Store objects with Indexes protobuf_parsers: (Dict[str, function]): key, value pair of key (str) --> pandas column name value (function) --> how to extract the value from the store The function should accept a Store object and return Any Returns: pd.DataFrame: The index and subindex data reformatted into a dataframe \"\"\" pandas_input = {} for store in data : # add metadata metadata = store . index . get_metadata () for key in metadata : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( metadata [ key ]) # add top level data from the reader for key in protobuf_parsers : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( protobuf_parsers [ key ]( store )) # load the data into a pandas dataframe return pd . DataFrame . from_dict ( pandas_input ) query_indexes ( query_index , ipfs ) staticmethod Query ipfs based on the query_index param. Parameters: Name Type Description Default query_index Index The Index object to use for the query. required ipfs Ipfs The IPFS client. required Returns: Type Description List [ Index ] List[Index]: The matching filenames found in ipfs, loaded into a list of Index objects Source code in src/store.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 @staticmethod def query_indexes ( query_index : Index , ipfs : Ipfs ) -> List [ Index ]: \"\"\"Query ipfs based on the `query_index` param. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. Returns: List[Index]: The matching filenames found in ipfs, loaded into a list of Index objects \"\"\" result = [] # list the files in the directory path = query_index . get_filename () response = ipfs . list_files ( path ) filenames = [ file [ 'Name' ] for file in response [ 'Entries' ]] for filename in filenames : # Listing the same file twice indicates the base case # ex: # path = `ls dir1/dir2` --> filenames = [\"filename\"] # path = `ls dir1/dir2/filename` --> filenames = [\"filename\"] if filename in path : return [ query_index ] # filter filenames based on the index full_filename = f \" { path } / { filename } \" . replace ( \"//\" , \"/\" ) from_index = Index . from_filename ( filename = full_filename , has_prefix = query_index . prefix ) if query_index . matches ( from_index ): result += Store . query_indexes ( from_index , ipfs ) return result query ( query_index , ipfs , reader ) staticmethod Query ipfs based on the query_index param. Find the filenames matching the query_index. Read the file contents from ipfs for each matching filename. Parse the file contents into the reader protobuf object. Parameters: Name Type Description Default query_index Index The Index object to use for the query. required ipfs Ipfs The IPFS client. required reader Message description required Yields: Type Description Iterator [ Store ] Iterator[Store]: The list of matching Store objects with file content loaded into the reader attribute Source code in src/store.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 @staticmethod def query ( query_index : Index , ipfs : Ipfs , reader : Message ) -> Iterator [ Store ]: \"\"\"Query ipfs based on the `query_index` param. Find the filenames matching the query_index. Read the file contents from ipfs for each matching filename. Parse the file contents into the reader protobuf object. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. reader (Message): _description_ Yields: Iterator[Store]: The list of matching Store objects with file content loaded into the `reader` attribute \"\"\" for response_index in Store . query_indexes ( query_index , ipfs ): store = Store ( index = response_index , reader = reader , ipfs = ipfs ) store . read () yield store","title":"Store"},{"location":"classes_store/#store","text":"","title":"Store"},{"location":"classes_store/#src.store.Store","text":"A utility to read/write protobuf data to ipfs. Reading: from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), reader=MyProtobuf() ) store.read() print(store.reader) Writing: from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), writer=MyProtobuf() ) store.add() Write with multiple indexes. Create a tiered file structure based on IDs. \u251c\u2500\u2500 fashion/ \u251c\u2500\u2500 designer_1.manufacturer_1 \u251c\u2500\u2500 designer_2.manufacturer_1 \u251c\u2500\u2500 deal_16.data \u251c\u2500\u2500 designer_4.manufacturer_3 \u251c\u2500\u2500 deal_1.data \u251c\u2500\u2500 deal_2.data from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal index = Index( prefix=\"fashion\", index={ \"designer\": str(uuid.uuid4()), \"manufacturer\": str(uuid.uuid4()) }, subindex=Index( index={ \"deal\": str(uuid.uuid4()) } ) ) data = Deal(type=Type.BUZZ, content=\"fizz\") store = Store(index=index, ipfs=Ipfs(), writer=data) store.add() Query the multiple indexes: Ex: get all deals with designer id \"123\" from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal query_index = Index( prefix=\"fashion\", index={ \"designer\": \"123\" } ) reader = Deal() store = Store.query(query_index, ipfs, reader) print(reader) Source code in src/store.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 @dataclass class Store (): \"\"\"A utility to read/write protobuf data to ipfs. Reading: ```py from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), reader=MyProtobuf() ) store.read() print(store.reader) ``` Writing: ```py from nanoswap.ipfskvs import Store, Index, Ipfs from myprotobuf_pb2 import MyProtobuf store = Store( Index.from_filename(\"myfile.txt\"), ipfs=Ipfs(host=\"127.0.0.1\", port=\"5001\"), writer=MyProtobuf() ) store.add() ``` Write with multiple indexes. Create a tiered file structure based on IDs. ``` \u251c\u2500\u2500 fashion/ \u251c\u2500\u2500 designer_1.manufacturer_1 \u251c\u2500\u2500 designer_2.manufacturer_1 \u251c\u2500\u2500 deal_16.data \u251c\u2500\u2500 designer_4.manufacturer_3 \u251c\u2500\u2500 deal_1.data \u251c\u2500\u2500 deal_2.data ``` ```py from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal index = Index( prefix=\"fashion\", index={ \"designer\": str(uuid.uuid4()), \"manufacturer\": str(uuid.uuid4()) }, subindex=Index( index={ \"deal\": str(uuid.uuid4()) } ) ) data = Deal(type=Type.BUZZ, content=\"fizz\") store = Store(index=index, ipfs=Ipfs(), writer=data) store.add() ``` Query the multiple indexes: Ex: get all deals with designer id \"123\" ```py from nanoswap.ipfskvs import Store, Index, Ipfs from deal_pb2 import Deal query_index = Index( prefix=\"fashion\", index={ \"designer\": \"123\" } ) reader = Deal() store = Store.query(query_index, ipfs, reader) print(reader) ``` \"\"\" index : Index writer : Message reader : Message def __init__ ( self : Self , index : Index , ipfs : Ipfs , writer : Message = None , reader : Message = None ) -> None : \"\"\"Construct a Store object. Args: index (Index): An object representing the filepath ipfs (Ipfs): The IPFS client writer (Message, optional): The protobuf object with the data to write to ipfs on `.write()`. Defaults to None. reader (Message, optional): The protobuf object to populate when reading the data from ipfs with `.read()`. Defaults to None. \"\"\" self . index = index self . ipfs = ipfs self . writer = writer self . reader = reader def read ( self : Self ) -> None : \"\"\"Read the data from ipfs into `self.reader`. Raises: FileNotFoundError: An exception is raised if the file is not found on IPFS. \"\"\" filename = self . index . get_filename () result = self . ipfs . read ( filename ) if not result : raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), filename ) self . reader . ParseFromString ( result ) def write ( self : Self ) -> None : \"\"\"Write the protobuf data from `self.writer` to IPFS.\"\"\" raise NotImplementedError ( \"For now, just use `add` and `delete`\" ) self . ipfs . write ( self . index . get_filename (), self . writer . SerializeToString () ) def add ( self : Self ) -> None : \"\"\"Add the protobuf data from `self.writer` to IPFS.\"\"\" self . ipfs . add ( self . index . get_filename (), self . writer . SerializeToString () ) def delete ( self : Self ) -> None : \"\"\"Only needed for local testing.\"\"\" self . ipfs . delete ( self . index . get_filename ()) @staticmethod def to_dataframe ( data : List [ Store ], protobuf_parsers : Dict [ str , FunctionType ]) -> pd . DataFrame : \"\"\"Convert a list of Store objects to a pandas dataframe. The data for each Store must be read into memory beforehand; using `store.read()` Args: data (List[Store]): The list of Store objects with Indexes protobuf_parsers: (Dict[str, function]): key, value pair of key (str) --> pandas column name value (function) --> how to extract the value from the store The function should accept a Store object and return Any Returns: pd.DataFrame: The index and subindex data reformatted into a dataframe \"\"\" pandas_input = {} for store in data : # add metadata metadata = store . index . get_metadata () for key in metadata : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( metadata [ key ]) # add top level data from the reader for key in protobuf_parsers : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( protobuf_parsers [ key ]( store )) # load the data into a pandas dataframe return pd . DataFrame . from_dict ( pandas_input ) @staticmethod def query_indexes ( query_index : Index , ipfs : Ipfs ) -> List [ Index ]: \"\"\"Query ipfs based on the `query_index` param. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. Returns: List[Index]: The matching filenames found in ipfs, loaded into a list of Index objects \"\"\" result = [] # list the files in the directory path = query_index . get_filename () response = ipfs . list_files ( path ) filenames = [ file [ 'Name' ] for file in response [ 'Entries' ]] for filename in filenames : # Listing the same file twice indicates the base case # ex: # path = `ls dir1/dir2` --> filenames = [\"filename\"] # path = `ls dir1/dir2/filename` --> filenames = [\"filename\"] if filename in path : return [ query_index ] # filter filenames based on the index full_filename = f \" { path } / { filename } \" . replace ( \"//\" , \"/\" ) from_index = Index . from_filename ( filename = full_filename , has_prefix = query_index . prefix ) if query_index . matches ( from_index ): result += Store . query_indexes ( from_index , ipfs ) return result @staticmethod def query ( query_index : Index , ipfs : Ipfs , reader : Message ) -> Iterator [ Store ]: \"\"\"Query ipfs based on the `query_index` param. Find the filenames matching the query_index. Read the file contents from ipfs for each matching filename. Parse the file contents into the reader protobuf object. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. reader (Message): _description_ Yields: Iterator[Store]: The list of matching Store objects with file content loaded into the `reader` attribute \"\"\" for response_index in Store . query_indexes ( query_index , ipfs ): store = Store ( index = response_index , reader = reader , ipfs = ipfs ) store . read () yield store","title":"Store"},{"location":"classes_store/#src.store.Store.__init__","text":"Construct a Store object. Parameters: Name Type Description Default index Index An object representing the filepath required ipfs Ipfs The IPFS client required writer Message The protobuf object with the data to write to ipfs on .write() . Defaults to None. None reader Message The protobuf object to populate when reading the data from ipfs with .read() . Defaults to None. None Source code in src/store.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def __init__ ( self : Self , index : Index , ipfs : Ipfs , writer : Message = None , reader : Message = None ) -> None : \"\"\"Construct a Store object. Args: index (Index): An object representing the filepath ipfs (Ipfs): The IPFS client writer (Message, optional): The protobuf object with the data to write to ipfs on `.write()`. Defaults to None. reader (Message, optional): The protobuf object to populate when reading the data from ipfs with `.read()`. Defaults to None. \"\"\" self . index = index self . ipfs = ipfs self . writer = writer self . reader = reader","title":"__init__()"},{"location":"classes_store/#src.store.Store.read","text":"Read the data from ipfs into self.reader . Raises: Type Description FileNotFoundError An exception is raised if the file is not found on IPFS. Source code in src/store.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def read ( self : Self ) -> None : \"\"\"Read the data from ipfs into `self.reader`. Raises: FileNotFoundError: An exception is raised if the file is not found on IPFS. \"\"\" filename = self . index . get_filename () result = self . ipfs . read ( filename ) if not result : raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), filename ) self . reader . ParseFromString ( result )","title":"read()"},{"location":"classes_store/#src.store.Store.add","text":"Add the protobuf data from self.writer to IPFS. Source code in src/store.py 149 150 151 152 153 154 def add ( self : Self ) -> None : \"\"\"Add the protobuf data from `self.writer` to IPFS.\"\"\" self . ipfs . add ( self . index . get_filename (), self . writer . SerializeToString () )","title":"add()"},{"location":"classes_store/#src.store.Store.delete","text":"Only needed for local testing. Source code in src/store.py 156 157 158 def delete ( self : Self ) -> None : \"\"\"Only needed for local testing.\"\"\" self . ipfs . delete ( self . index . get_filename ())","title":"delete()"},{"location":"classes_store/#src.store.Store.to_dataframe","text":"Convert a list of Store objects to a pandas dataframe. The data for each Store must be read into memory beforehand; using store.read() Parameters: Name Type Description Default data List [ Store ] The list of Store objects with Indexes required protobuf_parsers Dict [ str , FunctionType ] (Dict[str, function]): key, value pair of key (str) --> pandas column name value (function) --> how to extract the value from the store The function should accept a Store object and return Any required Returns: Type Description pd . DataFrame pd.DataFrame: The index and subindex data reformatted into a dataframe Source code in src/store.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @staticmethod def to_dataframe ( data : List [ Store ], protobuf_parsers : Dict [ str , FunctionType ]) -> pd . DataFrame : \"\"\"Convert a list of Store objects to a pandas dataframe. The data for each Store must be read into memory beforehand; using `store.read()` Args: data (List[Store]): The list of Store objects with Indexes protobuf_parsers: (Dict[str, function]): key, value pair of key (str) --> pandas column name value (function) --> how to extract the value from the store The function should accept a Store object and return Any Returns: pd.DataFrame: The index and subindex data reformatted into a dataframe \"\"\" pandas_input = {} for store in data : # add metadata metadata = store . index . get_metadata () for key in metadata : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( metadata [ key ]) # add top level data from the reader for key in protobuf_parsers : if key not in pandas_input : pandas_input [ key ] = [] pandas_input [ key ] . append ( protobuf_parsers [ key ]( store )) # load the data into a pandas dataframe return pd . DataFrame . from_dict ( pandas_input )","title":"to_dataframe()"},{"location":"classes_store/#src.store.Store.query_indexes","text":"Query ipfs based on the query_index param. Parameters: Name Type Description Default query_index Index The Index object to use for the query. required ipfs Ipfs The IPFS client. required Returns: Type Description List [ Index ] List[Index]: The matching filenames found in ipfs, loaded into a list of Index objects Source code in src/store.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 @staticmethod def query_indexes ( query_index : Index , ipfs : Ipfs ) -> List [ Index ]: \"\"\"Query ipfs based on the `query_index` param. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. Returns: List[Index]: The matching filenames found in ipfs, loaded into a list of Index objects \"\"\" result = [] # list the files in the directory path = query_index . get_filename () response = ipfs . list_files ( path ) filenames = [ file [ 'Name' ] for file in response [ 'Entries' ]] for filename in filenames : # Listing the same file twice indicates the base case # ex: # path = `ls dir1/dir2` --> filenames = [\"filename\"] # path = `ls dir1/dir2/filename` --> filenames = [\"filename\"] if filename in path : return [ query_index ] # filter filenames based on the index full_filename = f \" { path } / { filename } \" . replace ( \"//\" , \"/\" ) from_index = Index . from_filename ( filename = full_filename , has_prefix = query_index . prefix ) if query_index . matches ( from_index ): result += Store . query_indexes ( from_index , ipfs ) return result","title":"query_indexes()"},{"location":"classes_store/#src.store.Store.query","text":"Query ipfs based on the query_index param. Find the filenames matching the query_index. Read the file contents from ipfs for each matching filename. Parse the file contents into the reader protobuf object. Parameters: Name Type Description Default query_index Index The Index object to use for the query. required ipfs Ipfs The IPFS client. required reader Message description required Yields: Type Description Iterator [ Store ] Iterator[Store]: The list of matching Store objects with file content loaded into the reader attribute Source code in src/store.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 @staticmethod def query ( query_index : Index , ipfs : Ipfs , reader : Message ) -> Iterator [ Store ]: \"\"\"Query ipfs based on the `query_index` param. Find the filenames matching the query_index. Read the file contents from ipfs for each matching filename. Parse the file contents into the reader protobuf object. Args: query_index (Index): The Index object to use for the query. ipfs (Ipfs): The IPFS client. reader (Message): _description_ Yields: Iterator[Store]: The list of matching Store objects with file content loaded into the `reader` attribute \"\"\" for response_index in Store . query_indexes ( query_index , ipfs ): store = Store ( index = response_index , reader = reader , ipfs = ipfs ) store . read () yield store","title":"query()"}]}